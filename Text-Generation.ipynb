{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVTjUo7mwWW6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koushik\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4GoWMRCQwcPp",
    "outputId": "a98ea995-b5de-4a08-96c9-82b05c0a668e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, 'and what is the use of a book,' thought alice 'without pictures or\n",
      "conversations?'\n",
      "\n",
      "so she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure\n",
      "of making a daisy-chain would be worth the trouble of getting up and\n",
      "picking the daisies, when suddenly a white rabbit with pink eyes ran\n",
      "close by her.\n",
      "\n",
      "there was nothing so very remarkable in that; nor did alice think it so\n",
      "very much out of the way to hear the rabbit say to itself, 'oh dear!\n",
      "oh dear! i shall be late!' (when she thought it over afterwards, it\n",
      "occurred to her that she ought to have wondered at this, but at the time\n",
      "it all seemed quite natural); but when the rabbit actually took a watch\n",
      "out of its waistcoat-pocket, and looked at it, and \n"
     ]
    }
   ],
   "source": [
    "#Open the file and convert to lower characters\n",
    "filename = 'alice.txt'\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "print(raw_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7V5mXiGwhGN"
   },
   "outputs": [],
   "source": [
    "#For encoding and decoding we have to create a mapping dictionary from characters to integers and integer to characters\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
    "int_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "zFevXInwwjBh",
    "outputId": "f969798e-40b5-4c03-870d-42af6176c94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144286\n",
      "Total Vocabularies:  43\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, '*': 7, ',': 8, '-': 9, '.': 10, ':': 11, ';': 12, '?': 13, '[': 14, ']': 15, '_': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: '*', 8: ',', 9: '-', 10: '.', 11: ':', 12: ';', 13: '?', 14: '[', 15: ']', 16: '_', 17: 'a', 18: 'b', 19: 'c', 20: 'd', 21: 'e', 22: 'f', 23: 'g', 24: 'h', 25: 'i', 26: 'j', 27: 'k', 28: 'l', 29: 'm', 30: 'n', 31: 'o', 32: 'p', 33: 'q', 34: 'r', 35: 's', 36: 't', 37: 'u', 38: 'v', 39: 'w', 40: 'x', 41: 'y', 42: 'z'}\n"
     ]
    }
   ],
   "source": [
    "#print the summaries of the characters and vocabularies\n",
    "no_of_chars = len(raw_text)\n",
    "no_of_vocabulary = len(chars)\n",
    "print(\"Total Characters: \", no_of_chars)\n",
    "print(\"Total Vocabularies: \", no_of_vocabulary)\n",
    "print(chars)\n",
    "print(char_to_int)\n",
    "print(int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_umxawvHwlUw"
   },
   "outputs": [],
   "source": [
    "#preparing the dataset for input and output pairs as encoders and decoders\n",
    "seq_length = 100\n",
    "X_data = []\n",
    "y_data = []\n",
    "for i in range(0,no_of_chars-seq_length,1):\n",
    "  seq_in = raw_text[i:i+seq_length]\n",
    "  seq_out = raw_text[i+seq_length]\n",
    "  X_data.append([char_to_int[char] for char in seq_in])\n",
    "  y_data.append(char_to_int[seq_out])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6peAFji20du0",
    "outputId": "4efa712c-0c8e-4345-fe9d-52c263fa020d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns  144186\n"
     ]
    }
   ],
   "source": [
    "#print the number of patterns generated\n",
    "no_patterns = len(X_data)\n",
    "print(\"Number of patterns \",no_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q731tJO_0gzn",
    "outputId": "d3a664a0-967a-4ec9-c44a-91df0dd11c33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144186, 100, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape the X to be [samples,time steps,features]\n",
    "X = (numpy.reshape(X_data,(no_patterns,seq_length,1)))\n",
    "numpy.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zdBdsa-0jQU"
   },
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "X = (X /float(no_of_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kUdItsw0pNw"
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we define the checkpoint so that the trained model can be loaded later\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.text_gen2\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "3A2B23o-y6BQ",
    "outputId": "db479376-1e5a-47fa-a6c4-9ba910fe848a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "144186/144186 [==============================] - 358s 2ms/step - loss: 1.5886\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.58858, saving model to weights-improvement-01-1.5886.text_gen2\n",
      "Epoch 2/50\n",
      "144186/144186 [==============================] - 358s 2ms/step - loss: 1.5655\n",
      "\n",
      "Epoch 00002: loss improved from 1.58858 to 1.56553, saving model to weights-improvement-02-1.5655.text_gen2\n",
      "Epoch 3/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.5431\n",
      "\n",
      "Epoch 00003: loss improved from 1.56553 to 1.54312, saving model to weights-improvement-03-1.5431.text_gen2\n",
      "Epoch 4/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.5221\n",
      "\n",
      "Epoch 00004: loss improved from 1.54312 to 1.52213, saving model to weights-improvement-04-1.5221.text_gen2\n",
      "Epoch 5/50\n",
      "144186/144186 [==============================] - 361s 3ms/step - loss: 1.5041\n",
      "\n",
      "Epoch 00005: loss improved from 1.52213 to 1.50406, saving model to weights-improvement-05-1.5041.text_gen2\n",
      "Epoch 6/50\n",
      "144186/144186 [==============================] - 361s 3ms/step - loss: 1.4847\n",
      "\n",
      "Epoch 00006: loss improved from 1.50406 to 1.48467, saving model to weights-improvement-06-1.4847.text_gen2\n",
      "Epoch 7/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.4652\n",
      "\n",
      "Epoch 00007: loss improved from 1.48467 to 1.46523, saving model to weights-improvement-07-1.4652.text_gen2\n",
      "Epoch 8/50\n",
      "144186/144186 [==============================] - 362s 3ms/step - loss: 1.4461\n",
      "\n",
      "Epoch 00008: loss improved from 1.46523 to 1.44607, saving model to weights-improvement-08-1.4461.text_gen2\n",
      "Epoch 9/50\n",
      "144186/144186 [==============================] - 361s 3ms/step - loss: 1.4341\n",
      "\n",
      "Epoch 00009: loss improved from 1.44607 to 1.43407, saving model to weights-improvement-09-1.4341.text_gen2\n",
      "Epoch 10/50\n",
      "144186/144186 [==============================] - 362s 3ms/step - loss: 1.4170\n",
      "\n",
      "Epoch 00010: loss improved from 1.43407 to 1.41699, saving model to weights-improvement-10-1.4170.text_gen2\n",
      "Epoch 11/50\n",
      "144186/144186 [==============================] - 361s 3ms/step - loss: 1.4045\n",
      "\n",
      "Epoch 00011: loss improved from 1.41699 to 1.40453, saving model to weights-improvement-11-1.4045.text_gen2\n",
      "Epoch 12/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.3904\n",
      "\n",
      "Epoch 00012: loss improved from 1.40453 to 1.39036, saving model to weights-improvement-12-1.3904.text_gen2\n",
      "Epoch 13/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.3814\n",
      "\n",
      "Epoch 00013: loss improved from 1.39036 to 1.38139, saving model to weights-improvement-13-1.3814.text_gen2\n",
      "Epoch 14/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.3653\n",
      "\n",
      "Epoch 00014: loss improved from 1.38139 to 1.36532, saving model to weights-improvement-14-1.3653.text_gen2\n",
      "Epoch 15/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.3526\n",
      "\n",
      "Epoch 00015: loss improved from 1.36532 to 1.35256, saving model to weights-improvement-15-1.3526.text_gen2\n",
      "Epoch 16/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.3433\n",
      "\n",
      "Epoch 00016: loss improved from 1.35256 to 1.34333, saving model to weights-improvement-16-1.3433.text_gen2\n",
      "Epoch 17/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.3346\n",
      "\n",
      "Epoch 00017: loss improved from 1.34333 to 1.33464, saving model to weights-improvement-17-1.3346.text_gen2\n",
      "Epoch 18/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.3240\n",
      "\n",
      "Epoch 00018: loss improved from 1.33464 to 1.32403, saving model to weights-improvement-18-1.3240.text_gen2\n",
      "Epoch 19/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.3155\n",
      "\n",
      "Epoch 00019: loss improved from 1.32403 to 1.31548, saving model to weights-improvement-19-1.3155.text_gen2\n",
      "Epoch 20/50\n",
      "144186/144186 [==============================] - 361s 3ms/step - loss: 1.3069\n",
      "\n",
      "Epoch 00020: loss improved from 1.31548 to 1.30693, saving model to weights-improvement-20-1.3069.text_gen2\n",
      "Epoch 21/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2981\n",
      "\n",
      "Epoch 00021: loss improved from 1.30693 to 1.29812, saving model to weights-improvement-21-1.2981.text_gen2\n",
      "Epoch 22/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2923\n",
      "\n",
      "Epoch 00022: loss improved from 1.29812 to 1.29233, saving model to weights-improvement-22-1.2923.text_gen2\n",
      "Epoch 23/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.2869\n",
      "\n",
      "Epoch 00023: loss improved from 1.29233 to 1.28685, saving model to weights-improvement-23-1.2869.text_gen2\n",
      "Epoch 24/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.3075\n",
      "\n",
      "Epoch 00024: loss did not improve from 1.28685\n",
      "Epoch 25/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2728\n",
      "\n",
      "Epoch 00025: loss improved from 1.28685 to 1.27275, saving model to weights-improvement-25-1.2728.text_gen2\n",
      "Epoch 26/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2616\n",
      "\n",
      "Epoch 00026: loss improved from 1.27275 to 1.26164, saving model to weights-improvement-26-1.2616.text_gen2\n",
      "Epoch 27/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2568\n",
      "\n",
      "Epoch 00027: loss improved from 1.26164 to 1.25681, saving model to weights-improvement-27-1.2568.text_gen2\n",
      "Epoch 28/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2510\n",
      "\n",
      "Epoch 00028: loss improved from 1.25681 to 1.25102, saving model to weights-improvement-28-1.2510.text_gen2\n",
      "Epoch 29/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.2432\n",
      "\n",
      "Epoch 00029: loss improved from 1.25102 to 1.24323, saving model to weights-improvement-29-1.2432.text_gen2\n",
      "Epoch 30/50\n",
      "144186/144186 [==============================] - 361s 3ms/step - loss: 1.2386\n",
      "\n",
      "Epoch 00030: loss improved from 1.24323 to 1.23858, saving model to weights-improvement-30-1.2386.text_gen2\n",
      "Epoch 31/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2360\n",
      "\n",
      "Epoch 00031: loss improved from 1.23858 to 1.23602, saving model to weights-improvement-31-1.2360.text_gen2\n",
      "Epoch 32/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2304\n",
      "\n",
      "Epoch 00032: loss improved from 1.23602 to 1.23036, saving model to weights-improvement-32-1.2304.text_gen2\n",
      "Epoch 33/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2248\n",
      "\n",
      "Epoch 00033: loss improved from 1.23036 to 1.22482, saving model to weights-improvement-33-1.2248.text_gen2\n",
      "Epoch 34/50\n",
      "144186/144186 [==============================] - 359s 2ms/step - loss: 1.2196\n",
      "\n",
      "Epoch 00034: loss improved from 1.22482 to 1.21963, saving model to weights-improvement-34-1.2196.text_gen2\n",
      "Epoch 35/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2166\n",
      "\n",
      "Epoch 00035: loss improved from 1.21963 to 1.21658, saving model to weights-improvement-35-1.2166.text_gen2\n",
      "Epoch 36/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2112\n",
      "\n",
      "Epoch 00036: loss improved from 1.21658 to 1.21115, saving model to weights-improvement-36-1.2112.text_gen2\n",
      "Epoch 37/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2048\n",
      "\n",
      "Epoch 00037: loss improved from 1.21115 to 1.20479, saving model to weights-improvement-37-1.2048.text_gen2\n",
      "Epoch 38/50\n",
      "144186/144186 [==============================] - 360s 2ms/step - loss: 1.2011\n",
      "\n",
      "Epoch 00038: loss improved from 1.20479 to 1.20114, saving model to weights-improvement-38-1.2011.text_gen2\n",
      "Epoch 39/50\n",
      "144186/144186 [==============================] - 362s 3ms/step - loss: 1.2028\n",
      "\n",
      "Epoch 00039: loss did not improve from 1.20114\n",
      "Epoch 40/50\n",
      "144186/144186 [==============================] - 372s 3ms/step - loss: 1.1977\n",
      "\n",
      "Epoch 00040: loss improved from 1.20114 to 1.19773, saving model to weights-improvement-40-1.1977.text_gen2\n",
      "Epoch 41/50\n",
      "144186/144186 [==============================] - 376s 3ms/step - loss: 1.1978\n",
      "\n",
      "Epoch 00041: loss did not improve from 1.19773\n",
      "Epoch 42/50\n",
      "144186/144186 [==============================] - 391s 3ms/step - loss: 1.1938\n",
      "\n",
      "Epoch 00042: loss improved from 1.19773 to 1.19379, saving model to weights-improvement-42-1.1938.text_gen2\n",
      "Epoch 43/50\n",
      "144186/144186 [==============================] - 377s 3ms/step - loss: 1.1862\n",
      "\n",
      "Epoch 00043: loss improved from 1.19379 to 1.18624, saving model to weights-improvement-43-1.1862.text_gen2\n",
      "Epoch 44/50\n",
      "144186/144186 [==============================] - 380s 3ms/step - loss: 1.1861\n",
      "\n",
      "Epoch 00044: loss improved from 1.18624 to 1.18613, saving model to weights-improvement-44-1.1861.text_gen2\n",
      "Epoch 45/50\n",
      "144186/144186 [==============================] - 380s 3ms/step - loss: 1.1839\n",
      "\n",
      "Epoch 00045: loss improved from 1.18613 to 1.18391, saving model to weights-improvement-45-1.1839.text_gen2\n",
      "Epoch 46/50\n",
      "144186/144186 [==============================] - 380s 3ms/step - loss: 1.1772\n",
      "\n",
      "Epoch 00046: loss improved from 1.18391 to 1.17720, saving model to weights-improvement-46-1.1772.text_gen2\n",
      "Epoch 47/50\n",
      "144186/144186 [==============================] - 382s 3ms/step - loss: 1.1746\n",
      "\n",
      "Epoch 00047: loss improved from 1.17720 to 1.17460, saving model to weights-improvement-47-1.1746.text_gen2\n",
      "Epoch 48/50\n",
      "144186/144186 [==============================] - 382s 3ms/step - loss: 1.1723\n",
      "\n",
      "Epoch 00048: loss improved from 1.17460 to 1.17231, saving model to weights-improvement-48-1.1723.text_gen2\n",
      "Epoch 49/50\n",
      "144186/144186 [==============================] - 381s 3ms/step - loss: 1.1664\n",
      "\n",
      "Epoch 00049: loss improved from 1.17231 to 1.16641, saving model to weights-improvement-49-1.1664.text_gen2\n",
      "Epoch 50/50\n",
      "144186/144186 [==============================] - 380s 3ms/step - loss: 1.1732\n",
      "\n",
      "Epoch 00050: loss did not improve from 1.16641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b09b7f8be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=50,batch_size=128,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jVkEZSZfZxn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Koushik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Koushik\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Koushik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 800,555\n",
      "Trainable params: 800,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "new_model = keras.models.load_model('model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nmlLDrD3evSD",
    "outputId": "cfbd7fd9-d1a3-4701-eec2-7a9a21c03ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ly.\n",
      "\n",
      "'yes,' said alice, 'we learned french and music.'\n",
      "\n",
      "'and washing?' said the mock turtle.\n",
      "\n",
      "'certa \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed for generating the text\n",
    "start = numpy.random.randint(0, len(X_data)-1)\n",
    "pattern = X_data[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\",''.join([int_to_char[value] for value in pattern]),\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "7-sZPw5Y9_Vm",
    "outputId": "036bca36-9f37-4320-fa11-2d6e77ea01d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inly, i mnow that ' said alice, 'i mever keard the reason is it, i don't lnow that dorm that!'\n",
      "\n",
      "'i mead the rueen?' said the mock turtle. \n",
      "'not at all come and all ratsing of mint,' said alice, 'i mean the bouldr then in the listle gresn thme, and the mosal of the toil it. the rueen's prete out of the way of the little goass to them the had not about the tea that she had not about the table, and she was a little book with the gale. 'the rueen of the tort of the thalp biange the tay that sald at the mock turtle, and the trees said to the gale.\n",
      "\n",
      "'well, i suppose,' said alice, 'i mever keart there was the mock turtle so another, and the dreat hear of shehed to tea that she had been fornowsed to tee the had not about the thate.\n",
      "\n",
      "'i mever heard of the louse, in and then seamed to tay the tay,' and she senoeed ierself ay the fuecutioner sabe wou cat a little without as the could, and see how suadenly was not a mittle wite all her hacd again, and the thouleed had tome thme the had not about t\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "final = []\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x/float(no_of_vocabulary)\n",
    "\tprediction = new_model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "  #finale = ''.join(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text_generation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
